# -*- coding: utf-8 -*-
"""cnn_image_recognition_flowers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12XaSq6D3AzsAeo6IYxWJU5zd0Edky17u
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import pathlib

from sklearn.metrics import accuracy_score, precision_score, balanced_accuracy_score
from keras.preprocessing import image
from keras.backend import reverse
from keras.models import Sequential, load_model
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Rescaling, Resizing, Dropout, RandomFlip, RandomZoom, RandomRotation, BatchNormalization
from keras.optimizers import Adam
from keras.metrics import Precision, TopKCategoricalAccuracy
from keras.utils import load_img, img_to_array, get_file, image_dataset_from_directory #  https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory

from google.colab import drive
drive.mount('/content/gdrive')

dataset_url = "http://download.tensorflow.org/example_images/flower_photos.tgz"
data_dir = get_file(origin=dataset_url,
                                   fname='flower_photos',
                                   untar=True)
data_dir = pathlib.Path(data_dir)

image_count = len(list(data_dir.glob('*/*.jpg')))
print(F'{data_dir} contains {image_count} images')

batch_size=32
color_mode='rgb'
crop_to_aspect_ratio=True #resize the images without aspect ratio distortion
dropout_rate=0.1
epochs=100
img_height=256
img_width=256
interploration='bicubic' #https://en.wikipedia.org/wiki/Image_scaling
kernel_size = (3,3)
labels='inferred'
label_mode='categorical'
#max_norm_value=0.2
model_save_path = '/content/gdrive/MyDrive/KEA/Python Codebase/machine-learning/mandatories/py-ml-mand-2-cnn-flowers/models'
no_of_filters=64
optimizer=Adam(learning_rate=0.003)
seed=42
shuffle=True
strides=1
target_size=64
validation_split=0.20
flower_counts = {0: 633, 1: 898, 2: 641, 3: 699, 4: 799}

def make_dataset(subset_arg):
    return image_dataset_from_directory(
    data_dir,
    labels=labels,
    label_mode=label_mode, 
    color_mode=color_mode,
    batch_size=batch_size,
    image_size=(img_height, img_width),
    shuffle=shuffle,
    seed=seed,
    validation_split=validation_split,
    interpolation=interploration, 
    crop_to_aspect_ratio=crop_to_aspect_ratio,
    subset=subset_arg,
  )

train_set = make_dataset('training')
val_set = make_dataset('validation')
class_names=train_set.class_names
no_of_classes=len(class_names)

print(class_names)
plt.figure(figsize=(7, 7))
for images, labels in train_set.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.axis("off")

model = Sequential([
    Rescaling(1./255),
    RandomFlip('horizontal_and_vertical'),
    RandomRotation(0.2),
    RandomZoom(0.1),
    Resizing(target_size, target_size),
    Conv2D(no_of_filters, kernel_size, strides=strides, input_shape=[target_size, target_size, 3], activation='relu'),
    MaxPool2D(),
 #   BatchNormalization(),
    Dropout(dropout_rate),
    Conv2D(no_of_filters, kernel_size, strides=strides, input_shape=[target_size, target_size, 3], activation='relu'),
    MaxPool2D(),
  #  BatchNormalization(),
    Dropout(dropout_rate),
    Conv2D(no_of_filters, kernel_size, strides=strides, input_shape=[target_size, target_size, 3], activation='relu'),
    MaxPool2D(),  
 #   BatchNormalization(),
    Dropout(dropout_rate),  
    Flatten(),
    Dense(units=520, activation='relu'),
    Dense(no_of_classes, activation='softmax')
])

model.compile(
    optimizer=optimizer,
    loss='categorical_crossentropy',
    metrics=[Precision(name='precision'), TopKCategoricalAccuracy(k=2, name='topk'), 'categorical_accuracy'] 
)
model.summary()

history = model.fit(
    x=train_set, 
    validation_data=val_set,   
    epochs=epochs)

validation_result = model.evaluate(val_set)

from google.colab import drive
drive.mount('/content/gdrive')
model.save(f'{model_save_path}/flower_model_v_15.h5')

# https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#scrollTo=jWnopEChMMCn&line=6&uniqifier=1

acc = history.history['categorical_accuracy']
val_acc = history.history['val_categorical_accuracy']
topk_acc = history.history['topk']
val_topk = history.history['val_topk']

precision = history.history['precision']
val_precision = history.history['val_precision']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(24, 8))

#accuracy
ax = plt.subplot(1, 3, 1)
ax.set(ylim=[0.3, 0.95])
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.plot(epochs_range, topk_acc, label='Training TopK Accuracy')
plt.plot(epochs_range, val_topk, label='Validation TopK Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

#loss
ax2 = plt.subplot(1, 3, 2)
ax2.set(ylim=[0.3, 2])
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='lower right')
plt.title('Training and Validation Loss')

#precision
ax3 = plt.subplot(1, 3, 3)
ax3.set(ylim=[0.3, 0.9])
plt.plot(epochs_range, precision, label='Training Precision')
plt.plot(epochs_range, val_precision, label='Validation Precision')
plt.legend(loc='lower right')
plt.title('Training and Validation Precision')

plt.show()

def print_result(class_names, result):
  
  res_dict = dict(zip(class_names, result[0]))
  res_sorted = dict(sorted(res_dict.items(), key=lambda item: item[1], reverse=True))

  for k, v in res_sorted.items():
      print(f'{k.ljust(20)} : {v:.5f}')

@tf.autograph.experimental.do_not_convert
def single_img_predict(img_path):
  test_image = load_img(img_path, target_size=[img_height, img_width], color_mode=color_mode)
  test_image = img_to_array(test_image)
  test_image = np.expand_dims(test_image,axis=0)

  result = model.predict(test_image/255.0)

  print_result(class_names, result)

print('daisy')
single_img_predict('/root/.keras/datasets/flower_photos/daisy/1354396826_2868631432_m.jpg')
print('')
print('dandelion')
single_img_predict('/root/.keras/datasets/flower_photos/dandelion/8647874151_aac8db2588_m.jpg')
print('')
print('roses')
single_img_predict('/root/.keras/datasets/flower_photos/roses/3576488381_611f3446e0_n.jpg')
print('')
print('sunflowers')
single_img_predict('/root/.keras/datasets/flower_photos/sunflowers/6122711533_2c219f0392_n.jpg')
print('')
print('tulips')
single_img_predict('/root/.keras/datasets/flower_photos/tulips/518256494_368a72db37.jpg')